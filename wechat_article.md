拒绝虚火，Vibe Coding法律AI需要引入工程师文化 

最近圈子里Vibe Coding很火，仿佛只要会写Prompt，人人都能手搓一个SaaS。

说句可能得罪人的话：现在的法律AI圈子，太浮躁了。

很多律师朋友，甚至很多创业者，觉得有了大模型，有了Cursor，就能颠覆法律行业了。他们沉迷于各种Skills，却唯独忽略了AI应用落地最枯燥、最基础、但也最重要的东西——**工程师文化与工程师精神**。

之前写了我与法律AI的故事和个人思考上篇和中篇，但一直迟迟没写下篇。本来想写写我创业做数据基础设施的心得体会（比如Judge Model和Reward Model的训练、行业Bench的构建方法），但总觉得离律师圈还是有点远。因为最近有项目涉及评测paddleocr-vl-1.5b和glm-ocr的模型能力，这个下篇正好就拿我最近开源的一个Vibe Coding的项目：**Legal Redaction** 展开说说，以及谈谈我对"Vibe Coding & 法律AI"这件事的重新思考。

我这个项目叫Legal Redaction，但其实是可以脱敏一切想要脱敏的东西。现在我把这个平台及工程框架开源，也是展现我作为数据基础设施建设方所承载的责任，因为高质量数据集的前提是有个人信息保护、敏感信息保护的要求，希望这套开源技术除了赋能法律老本行以外，能够对数据集建设方有参考或者借鉴意义。

---

01
绝大部分法律人的Vibe Coding做不出企业级应用

打开GitHub，满地都是套壳的OpenClaw或者一眼看上去就是AI生成的那种紫色+黑体字，已经有点审美疲劳了。再加上创新点实在是很差，很多仍旧是在模型能力上，只不过现在叠加了更多的概念buff，从之前的MCP到现在的Skills，很多人不知道模型能力上限在哪、下限在哪，该怎么样以应用为导向选择最佳的解决方案。

以前在做Legal NLP时候，我就发现，法律人做AI，最容易陷入"文科生思维"，我把它叫做**“法条思维”**。

“法条思维”的本质是教义法学背景下，过分依赖规则，也就是正则实现。因此我刷到很多脱敏项目，无一例外的，都是配置好映射关系，最后统一替换，比如某款叫做脱敏宝的软件。

我两眼一黑，这不是我五年前刚接触Legal NLP前，所谓的法律科技公司在做的事情吗？都大模型时代了，怎么还是这套东西。

稍微好一点的脱敏软件开始训命名实体识别（NER）模型，值得欣慰的是这批同学跑完了我五年前训练NER的全流程，沉淀下了丰富的工程经验。但实际上技术最前沿已经是拿0.6B的大模型把NER和指代消解都做了，比如玄武实验室发布的HaS模型。

《雪中悍刀行》里有句话：**“蠢才！手指便是剑。那招‘金玉满堂’，定要用剑才能使吗？”**

乍一看，脱敏不就是让大模型把名字、身份证号找出来替换掉吗？写个正则表达式或者Prompt不就完了？如果你真这么干，其实就是为了发布而发布，根本落不了地。

02
硬核技术拆解：拒绝“端到端”的盲目崇拜

很多Vibe Coding的玩家喜欢追求“All in One”，把图片扔给GPT-4o，让它直接返回脱敏后的图片。这在Demo里很酷，但在工程上是灾难。

为什么？因为贵，因为慢，因为不可控。

在Legal Redaction里，我没有迷信大模型，而是设计了一套**“双Pipeline混合检测架构”**，这才是这个项目的技术灵魂。你可以把它理解为律所里的“流水线分工”：

**第一路：极其严谨的“文字质检员” (PaddleOCR-VL + HaS)**

这一路负责处理90%的常规文本。我没有用大模型硬抗，而是选用了百度开源的**PaddleOCR-VL-1.5**。
*   **它的任务**：只干一件事，把字认准，把坐标（x, y, w, h）框死。它能提供像素级的精确度，这是大模型目前做不到的。
*   **它的搭档**：拿到文字后，我接入了玄武实验室的**HaS-4.0 (Qwen3-0.6B)** 模型。这是一个专门针对隐私实体微调的小模型。它不只是正则匹配，它懂语义。比如“张三”这两个字，在合同首部是“甲方”，在落款是“授权代表”，正则可能会漏，但HaS能基于上下文精准识别。

**第二路：直觉敏锐的“图像审核员” (GLM-4V)**

这一路负责处理剩下的10%“硬骨头”。
*   **它的任务**：寻找那些OCR看不懂的东西——**红色的公章、潦草的手写签名、按得歪歪扭扭的指纹、甚至是身份证上的头像照片**。
*   **它的核心**：我使用了量化版的**GLM-4.6V-Flash**。它能像人眼一样，“看”到图片里的视觉元素。OCR眼里是一团噪点的地方，在它眼里就是“一枚直径4cm的圆形公章”。

**最后一步：IoU 融合裁决**

两条流水线并行工作，最后汇合。这时候工程逻辑就进场了：我们通过计算**IoU（交并比）**来做决策。
*   如果OCR说这是文字，VLM说这是图片，位置重叠了怎么办？
*   我的策略是：**信OCR的坐标精度，信VLM的召回广度**。

这种“双保险”机制，确保了在保护隐私时，既不会因为OCR眼瞎而漏掉公章，也不会因为大模型幻觉而把无辜的文字抹黑。

03
工程师精神：是在失败的Bad Case里找生路

什么叫工程师文化？不是你会调包，而是你能搞定那些恶心的**Bad Case**。

在开发过程中，我遇到过一个让我抓狂的场景：**低像素的电子病历扫描件**。

医生那狂野的草书，加上扫描件的噪点，直接把PaddleOCR干沉默了，识别出来全是乱码。于是我想，既然OCR不行，那就上VLM（视觉大模型）吧。

**第一次尝试：GLM-4V 直接上**
我让GLM-4V直接读取图片。结果它神了，居然认出了医生写的字（大模型的泛化能力确实强）。但是！当我要求它返回坐标进行遮盖时，它开始**“瞎指”**。它告诉我在(100, 200)，实际那行字在(150, 250)。
**结论**：VLM 认字强，定位弱。

**第二次尝试：引入 PP-Structure V3 辅助**
我不死心。我想，既然VLM定位不准，那我就找个专门做版面分析的模型**PP-Structure V3**，先让它把“文本块”框出来，作为锚点，再让VLM去填空。
理论上很完美：PP-Structure 定框，GLM-4V 填肉。
**现实很骨感**：PP-Structure 的版面切分逻辑太机械了。它经常把公章和底下的文字切成一个大框，或者把一行连笔字切成三截。VLM 拿着这些错误的框，依然无法精准定位敏感信息。

虽然这几次尝试都以失败告终，最终我还是回到了“双Pipeline互补 + 交互式人工修正”的务实路线上。但正是这些失败的尝试，让我摸清了现有技术的边界。

**所谓的工程师精神，不是只展示成功的Demo，而是坦诚地面对Bad Case，并在成本、效果和可行性之间，通过无数次像这样的“缝缝补补”，找到那个勉强能用的最优解。**

04
基础设施才是法律AI的"里子"

我现在创业做的事情，是支撑国家数据局的高质量数据集评测。听起来好像离法律业务远了，但其实更近了。

在金杜的那几年，是我职业生涯中最宝贵的时光。我至今非常感谢金杜的IT团队，我的老板们，是他们教会了我什么是"基础设施"。

当时我从0到1搭建私有化模型产线，从硬件采购、环境搭建、安全加固，到数据标注、模型训练、推理调优。这些"脏活累活"，才是支撑上层AI应用跑起来的骨架。

现在很多律师想做AI，想创业，往往缺乏这种"工程师文化"。

大家都在谈论"大模型"，却很少有人谈论"数据治理"；大家都在谈论"颠覆"，却很少有人谈论"稳定性"。

Legal Redaction之所以坚持全链路本地推理，不依赖任何云端API，甚至考虑CPU或端侧推理（llama.cpp支持端侧）、尝试显存的极致压缩（因为考虑每个笔记本部署一个），就是基于这种基础设施思维。

05
关于Legal Redaction开源项目

这个项目我把它开源了，地址在GitHub：**TracyWang95/legal-redaction**。

它不是一个简单的Demo，而是一个可以直接拿去用的工具。同时支持所有商业化公司基于其二次开发做商业化。

它能做什么？
1.  **全本地运行**：断网也能跑，不用担心客户合同泄露。
2.  **混合检测**：不仅能脱敏文字，还能自动识别并遮盖公章、手写签名、指纹。
3.  **交互式编辑**：机器不准的地方，人可以微调。

技术栈上，我选了PaddleOCR-VL做底座，配合xuanwulab的HaS模型做NER，再挂一个量化版的GLM-4.6V做视觉补充。这套组合拳，是我在无数次失败中摸索出来的"最优解"。

我把它开源出来，一是觉得自己做得还挺满意的，想分享给有品味的技术人；二是希望给行业打个样——

**别再整那些虚头巴脑的Prompt/Skill工程了，沉下心来，搞点实实在在的工程建设。**

06
写在最后

我现在虽然身份变了，更多是站在数据基础设施建设的角度看问题，但"法律人+技术人"的底色没变。

我希望Legal Redaction能成为一个小小的支点，让大家看到：

法律AI的尽头，不是聊天机器人，而是扎扎实实的数据治理和工程落地。

**“前人曾照我，我照后来者，万古唱作慷概歌。”**

GitHub: TracyWang95/legal-redaction

作者：Tracy-王吴越
（此处保留原有的详细简介）

· END ·
