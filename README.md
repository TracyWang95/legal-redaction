# Legal Redaction 法律文件脱敏平台

<p align="center">
  <strong>面向律师的智能文件脱敏平台</strong><br>
  支持 Word / PDF / 图片敏感信息识别与脱敏处理<br>
  <b>全链路本地推理，无云端依赖</b>
</p>

---

## ✨ 功能特性

| 模块 | 说明 |
|------|------|
| 📄 **多格式支持** | Word (.doc/.docx)、PDF、图片 (.jpg/.png) |
| 🧠 **OCR + NER 双引擎** | PaddleOCR-VL-1.5（文字识别）+ HaS 4.0（命名实体识别） |
| 👁️ **本地视觉识别** | GLM-4.6V-Flash（签名/公章/指纹/二维码/广告水印等） |
| ✏️ **交互式编辑** | 识别结果可选 / 可编辑 / 可拉框调整 |
| 🔄 **脱敏模式** | 智能替换 / 掩码 / 结构化替换 |
| 📊 **对比与导出** | 脱敏前后对比预览、下载 |
| 🧪 **测试用例** | `testdata/ce.png` |

---

## 🏗️ 架构总览

本项目采用**双 Pipeline 混合检测架构**，将 OCR 文字识别、NER 语义理解、视觉大模型三者有机结合，实现对法律文书中各类敏感信息的精准定位与脱敏。

```
┌─────────────────────────────────────────────────────────────────────────┐
│                           用户上传文件                                    │
│                    (Word / PDF / 图片)                                   │
└─────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────┐
│                         文件解析 & 图像提取                               │
└─────────────────────────────────────────────────────────────────────────┘
                                    │
                    ┌───────────────┴───────────────┐
                    ▼                               ▼
    ┌───────────────────────────┐   ┌───────────────────────────┐
    │   Pipeline 1: OCR + HaS   │   │  Pipeline 2: GLM Vision   │
    │   (文字类敏感信息)          │   │  (视觉类敏感信息)          │
    └───────────────────────────┘   └───────────────────────────┘
                    │                               │
                    ▼                               ▼
    ┌───────────────────────────┐   ┌───────────────────────────┐
    │  PaddleOCR-VL-1.5         │   │  GLM-4.6V-Flash           │
    │  ├─ 文字检测 + 识别        │   │  ├─ 公章/印章检测          │
    │  ├─ 版面分析              │   │  ├─ 手写签名识别           │
    │  └─ 精确坐标定位           │   │  ├─ 指纹/照片检测          │
    └───────────────────────────┘   │  └─ 二维码/水印识别        │
                    │               └───────────────────────────┘
                    ▼                               │
    ┌───────────────────────────┐                   │
    │  HaS 4.0 (Qwen3-0.6B)     │                   │
    │  ├─ 命名实体识别 (NER)     │                   │
    │  ├─ 语义理解              │                   │
    │  └─ 指代消解              │                   │
    └───────────────────────────┘                   │
                    │                               │
                    ▼                               ▼
    ┌───────────────────────────┐   ┌───────────────────────────┐
    │  文字匹配定位              │   │  坐标归一化               │
    │  (实体 → OCR 坐标)        │   │  (0-1 相对坐标)           │
    └───────────────────────────┘   └───────────────────────────┘
                    │                               │
                    └───────────────┬───────────────┘
                                    ▼
                    ┌───────────────────────────────┐
                    │      IoU 去重 & 结果融合       │
                    │  (OCR 优先，GLM 补充)          │
                    └───────────────────────────────┘
                                    │
                                    ▼
                    ┌───────────────────────────────┐
                    │      交互式编辑 & 脱敏应用      │
                    └───────────────────────────────┘
```

---

## 🔬 脱敏算法详解

### 1. 双 Pipeline 混合检测

法律文书中的敏感信息可分为两大类：

| 类别 | 敏感信息类型 | 检测方式 |
|------|-------------|---------|
| **文字类** | 姓名、身份证号、电话、银行卡号、地址、公司名等 | OCR + HaS NER |
| **视觉类** | 公章、签名、指纹、照片、二维码、水印等 | GLM Vision |

传统 OCR 方案只能识别文字，无法处理印章、签名等视觉元素；而纯视觉大模型虽然能识别图像内容，但在精确定位文字边界上存在误差。本项目将两者优势结合：

- **OCR + HaS Pipeline**：擅长精准定位文字类敏感信息，坐标精确到像素级
- **GLM Vision Pipeline**：擅长识别视觉类敏感元素，弥补 OCR 的盲区

两条 Pipeline **并行运行**，最后通过 IoU（交并比）算法去重融合，确保不遗漏、不重复。

### 2. OCR + HaS Pipeline 工作流程

这是处理文字类敏感信息的核心流程：

```
原始图像
    │
    ▼
┌─────────────────────────────────────────────────────────────┐
│  Step 1: PaddleOCR-VL 文字检测                               │
│  ─────────────────────────────────────────────────────────  │
│  • 检测图像中所有文字区域                                      │
│  • 识别文字内容                                              │
│  • 返回每个文字块的精确坐标 (四边形顶点)                        │
│  • 同时检测公章等视觉元素                                      │
└─────────────────────────────────────────────────────────────┘
    │
    │  输出: [{text: "张三", polygon: [[x1,y1]...]}, ...]
    ▼
┌─────────────────────────────────────────────────────────────┐
│  Step 2: HaS 命名实体识别 (NER)                              │
│  ─────────────────────────────────────────────────────────  │
│  • 将所有 OCR 文字拼接成完整文本                               │
│  • 调用 HaS 模型进行语义分析                                   │
│  • 识别敏感实体类型（人名、身份证、电话等）                       │
│  • 支持自定义实体类型                                         │
└─────────────────────────────────────────────────────────────┘
    │
    │  输出: [{type: "PERSON", text: "张三"}, {type: "PHONE", text: "13800138000"}]
    ▼
┌─────────────────────────────────────────────────────────────┐
│  Step 3: 实体-坐标匹配                                       │
│  ─────────────────────────────────────────────────────────  │
│  • 在 OCR 文字块中查找每个敏感实体                             │
│  • 精确匹配：entity_text in block_text                       │
│  • 模糊匹配：SequenceMatcher > 0.85 (处理 OCR 识别误差)        │
│  • 子词定位：根据字符位置比例计算像素坐标                        │
└─────────────────────────────────────────────────────────────┘
    │
    │  输出: [{type: "PERSON", text: "张三", x: 100, y: 200, w: 50, h: 20}]
    ▼
┌─────────────────────────────────────────────────────────────┐
│  Step 4: 正则规则补充                                        │
│  ─────────────────────────────────────────────────────────  │
│  • 身份证号: [1-9]\d{5}(19|20)\d{2}(0[1-9]|1[0-2])...        │
│  • 手机号: 1[3-9]\d{9}                                       │
│  • 银行卡号: [3-6]\d{15,18}                                  │
│  • 邮箱: [a-zA-Z0-9._%+-]+@...                               │
│  • 与 NER 结果合并去重                                        │
└─────────────────────────────────────────────────────────────┘
```

**为什么要分离 OCR 和 NER？**

这是本项目的核心设计理念。传统方案让大模型同时做 OCR 和 NER，但这会导致：
- 坐标不精确（大模型返回的坐标常有偏差）
- 推理速度慢（视觉+语言双重计算）
- 难以处理复杂版面（表格、多栏等）

本项目采用**分工协作**策略：
- **PaddleOCR-VL**：专注文字检测，提供像素级精确坐标
- **HaS**：专注语义理解，识别敏感实体类型
- **文字匹配**：将两者结果关联，实现精准定位

### 3. GLM Vision Pipeline 工作流程

处理视觉类敏感信息：

```
原始图像
    │
    ▼
┌─────────────────────────────────────────────────────────────┐
│  GLM-4.6V-Flash 视觉检测                                     │
│  ─────────────────────────────────────────────────────────  │
│  • 输入：图像 + 检测类型提示词                                 │
│  • 输出：敏感区域坐标 (归一化 0-1)                             │
│  • 支持类型：公章、签名、指纹、照片、二维码、水印等              │
└─────────────────────────────────────────────────────────────┘
    │
    │  输出: [{type: "SEAL", x: 0.7, y: 0.8, w: 0.15, h: 0.1}]
    ▼
┌─────────────────────────────────────────────────────────────┐
│  坐标自适应处理                                              │
│  ─────────────────────────────────────────────────────────  │
│  • 自动识别坐标模式 (0-1 / 0-1000 / 像素)                     │
│  • 统一归一化到 0-1 相对坐标                                  │
│  • 边界修正 (确保不超出图像范围)                               │
└─────────────────────────────────────────────────────────────┘
```

### 4. 结果融合与去重

两条 Pipeline 的结果需要智能融合：

```python
def deduplicate_boxes(boxes, iou_threshold=0.3):
    """
    去重策略：
    1. OCR 结果全部保留（坐标更精确）
    2. GLM 结果：只保留与 OCR 不重叠的
    3. 重叠判断：IoU > 0.3 视为重复
    """
    ocr_boxes = [b for b in boxes if b.source == "ocr_has"]
    glm_boxes = [b for b in boxes if b.source == "glm_vision"]
    
    result = list(ocr_boxes)  # OCR 优先
    
    for glm_box in glm_boxes:
        is_duplicate = any(
            calculate_iou(glm_box, ocr_box) > iou_threshold
            for ocr_box in ocr_boxes
        )
        if not is_duplicate:
            result.append(glm_box)
    
    return result
```

### 5. 敏感信息分类体系

基于 **GB/T 37964-2019《信息安全技术 个人信息去标识化指南》** 构建：

| 分类 | 类型 ID | 说明 | 检测方式 |
|------|---------|------|---------|
| **直接标识符** | PERSON | 姓名 | HaS NER |
| | ID_CARD | 身份证号 | 正则 + NER |
| | PHONE | 电话号码 | 正则 + NER |
| | EMAIL | 电子邮箱 | 正则 |
| | BANK_CARD | 银行卡号 | 正则 + NER |
| | BANK_ACCOUNT | 银行账号 | NER |
| **准标识符** | COMPANY | 公司名称 | NER |
| | ADDRESS | 详细地址 | NER |
| | DATE | 日期 | 正则 + NER |
| | LICENSE_PLATE | 车牌号 | 正则 |
| | CASE_NUMBER | 案件编号 | NER |
| **视觉元素** | SEAL | 公章/印章 | GLM Vision |
| | SIGNATURE | 手写签名 | GLM Vision |
| | FINGERPRINT | 指纹 | GLM Vision |
| | PHOTO | 照片/头像 | GLM Vision |
| | QR_CODE | 二维码 | GLM Vision |

---

## 📦 模型与 Pipeline

| Pipeline | 模型 | 用途 | 端口 |
|----------|------|------|------|
| **OCR** | PaddleOCR-VL-1.5 | 文字检测与识别 | 8082 |
| **NER** | HaS 4.0 (Qwen3-0.6B) | 命名实体识别 | 8080 |
| **Vision** | GLM-4.6V-Flash-Q4_K_M | 视觉敏感区域检测 | 8081 |

---

## 🚀 快速开始

### 环境要求

- **操作系统**：Windows 10/11 或 Linux（WSL2 可选）
- **Python**：3.10+
- **Node.js**：18+
- **GPU**：NVIDIA（建议 RTX 4060 及以上，8GB+ 显存）

### 目录结构（建议）

```
<你的工作目录>/
├── llama.cpp/                  # llama.cpp 可执行文件
│   └── llama-server.exe        # 或 llama-server（Linux）
├── glm-models/                 # GLM 模型权重
│   ├── GLM-4.6V-Flash-Q4_K_M.gguf
│   └── mmproj-F16.gguf
└── legal-redaction/            # 本项目
    ├── backend/
    ├── frontend/
    └── ...
```

> **提示**：以下命令中的路径请根据你的实际目录结构调整。

---

### 1️⃣ 启动 GLM Vision（本地视觉服务）

```bash
# Windows PowerShell
cd <llama.cpp目录>
.\llama-server.exe ^
  -m <glm-models目录>\GLM-4.6V-Flash-Q4_K_M.gguf ^
  --mmproj <glm-models目录>\mmproj-F16.gguf ^
  --port 8081 -ngl 99 --ctx-size 4096 --jinja ^
  --flash-attn on --reasoning-budget 0 --mlock -np 1 -ub 1024
```

```bash
# Linux / WSL2
./llama-server \
  -m ../glm-models/GLM-4.6V-Flash-Q4_K_M.gguf \
  --mmproj ../glm-models/mmproj-F16.gguf \
  --port 8081 -ngl 99 --ctx-size 4096 --jinja \
  --flash-attn on --reasoning-budget 0 --mlock -np 1 -ub 1024
```

---

### 2️⃣ 启动 HaS（本地 NER 服务）

```bash
# Windows
.\llama-server.exe -hf xuanwulab/HaS_4.0_0.6B_GGUF --port 8080 -ngl 99
```

```bash
# Linux / WSL2
./llama-server -hf xuanwulab/HaS_4.0_0.6B_GGUF --port 8080 -ngl 99
```

---

### 3️⃣ 启动后端

```bash
cd backend
python -m venv venv        # 或使用 conda
source venv/bin/activate   # Windows: venv\Scripts\activate
pip install -r requirements.txt

# 启动 OCR 微服务（端口 8082）
python -m uvicorn ocr_server:app --host 0.0.0.0 --port 8082 &

# 启动主后端（端口 8000）
python -m uvicorn app.main:app --host 0.0.0.0 --port 8000
```

---

### 4️⃣ 启动前端

```bash
cd frontend
npm install
npm run dev -- --port 3000
```

访问：**http://localhost:3000**

---

## 🛠️ 本地模型部署踩坑记录

### GLM-4.6V-Flash（重点）

| 问题 | 解决方案 |
|------|----------|
| `unknown projector type: glm4v` | 使用 **b7897+** 版本的 llama.cpp（旧版不支持 glm4v） |
| 视觉识别无响应 | 必须带 `--mmproj mmproj-F16.gguf` |
| `expected value for argument` | `--flash-attn` 新版必须写成 `--flash-attn on` |
| 推理速度慢 | 添加 `--reasoning-budget 0` 关闭思考过程 |
| 输出英文而非中文 | 后端已内置 system prompt 强制中文输出 |

**模型下载**：
- 主模型：[GLM-4.6V-Flash-Q4_K_M.gguf](https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF)
- 视觉投影：同仓库的 `mmproj-F16.gguf`

---

### PaddleOCR-VL-1.5

- 首次启动时会自动下载到本地缓存（约 2GB）
- 后续运行会复用缓存，无需重复下载

---

### HaS（Qwen3-0.6B）

- 通过 llama-server 的 `-hf` 参数自动拉取
- 后端默认连接 `http://127.0.0.1:8080/v1`

---

## 🧪 环境检查

Windows PowerShell：

```powershell
.\scripts\check_env.ps1
```

脚本会检查：
- Python / Node / npm
- NVIDIA 驱动
- 模型文件是否存在
- 各服务端口是否监听

---

## 🧪 冒烟测试

详见：`tests/smoke_test.md`

测试用例：`testdata/ce.png`

---

## 📁 项目结构

```
legal-redaction/
├── backend/                 # FastAPI 后端
│   ├── app/
│   │   ├── api/             # API 路由
│   │   ├── core/            # 配置、GLM/HaS 客户端
│   │   └── services/        # 业务逻辑
│   │       ├── vision_service.py      # 双 Pipeline 调度
│   │       ├── hybrid_vision_service.py # OCR+HaS 混合服务
│   │       ├── ocr_service.py         # PaddleOCR 客户端
│   │       └── has_service.py         # HaS NER 服务
│   ├── ocr_server.py        # OCR 微服务入口
│   └── requirements.txt
├── frontend/                # React + Vite 前端
│   ├── src/
│   │   ├── components/      # 通用组件
│   │   └── pages/           # 页面
│   └── package.json
├── scripts/                 # 环境检查脚本
├── testdata/                # 测试用例
└── tests/                   # 测试模板
```

---

## 📖 API 文档

- **Swagger UI**：http://localhost:8000/docs
- **ReDoc**：http://localhost:8000/redoc

---

## 🎯 适用场景

本项目特别适合以下业务场景：

| 场景 | 说明 |
|------|------|
| **律所文书脱敏** | 合同、判决书、起诉状等法律文书的批量脱敏 |
| **证据材料处理** | 身份证、银行流水、合同扫描件的敏感信息遮盖 |
| **档案数字化** | 历史纸质档案扫描后的隐私保护 |
| **数据合规** | 满足 GDPR、《个人信息保护法》等合规要求 |

---

## 🤝 贡献

欢迎 Issue 与 PR！详见 [CONTRIBUTING.md](./CONTRIBUTING.md)

---

## 📄 许可证

[MIT License](./LICENSE)

---

## ⭐ Star History

如果这个项目对你有帮助，请点个 Star ⭐
